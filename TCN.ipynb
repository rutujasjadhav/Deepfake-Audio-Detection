{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNGXq4dMlItR"
   },
   "source": [
    "**TCN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vstVZcOQ5HB",
    "outputId": "256602ca-23e5-4cb6-8dab-bc6826f20538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCNModel(\n",
      "  (network): Sequential(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1): ReLU()\n",
      "    (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (max_pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu2): ReLU()\n",
      "    (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (max_pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu3): ReLU()\n",
      "    (batch_norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (max_pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=32768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TCNModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_channels, num_classes):\n",
    "        super(TCNModel, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(num_channels)):\n",
    "            conv_layer = nn.Conv2d(input_channels if i == 0 else num_channels[i-1],\n",
    "                                   num_channels[i],\n",
    "                                   kernel_size=(3, 3),\n",
    "                                   padding=(1, 1))\n",
    "            relu_layer = nn.ReLU()\n",
    "            bn_layer = nn.BatchNorm2d(num_channels[i])\n",
    "            pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "            # Append named layers to the list\n",
    "            layers.append((f'conv{i+1}', conv_layer))\n",
    "            layers.append((f'relu{i+1}', relu_layer))\n",
    "            layers.append((f'batch_norm{i+1}', bn_layer))\n",
    "            layers.append((f'max_pool{i+1}', pool_layer))\n",
    "\n",
    "        # Use OrderedDict to preserve layer names in nn.Sequential\n",
    "        from collections import OrderedDict\n",
    "        self.network = nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "        # Calculating the flattened output size dynamically\n",
    "        dummy_input = torch.randn(1, input_channels, 128, 128)\n",
    "        output_shape = self.network(dummy_input).view(1, -1).shape[1]\n",
    "\n",
    "        self.fc = nn.Linear(output_shape, num_classes)  # Using the calculated output size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "num_channels = [32, 64, 128]\n",
    "\n",
    "model = TCNModel(input_channels=1, num_channels, num_classes=2)\n",
    "print(model)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
