{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Change the paths in Data Loader fake_dir and real_dir to STFT/MFCC/Melspectrogram as required"
      ],
      "metadata": {
        "id": "ixw_7viLfdKf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXqcG2yjgAM1"
      },
      "source": [
        "Import Stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvM8tkjOiM1l"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio pytorch-tcn\n",
        "#Run this block if the following doesn't work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZs0tTPEiPPr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from pytorch_tcn import TCN\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvs_VVDelBsi"
      },
      "source": [
        "**DATASET Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwHKgCZIk-tM"
      },
      "outputs": [],
      "source": [
        "class SpectrogramDataset(Dataset):\n",
        "    def __init__(self, real_dir, fake_dir, transform=None):\n",
        "        self.real_dir = real_dir\n",
        "        self.fake_dir = fake_dir\n",
        "        self.real_images = [f for f in os.listdir(real_dir) if not os.path.isdir(os.path.join(real_dir, f))]\n",
        "        self.fake_images = [f for f in os.listdir(fake_dir) if not os.path.isdir(os.path.join(fake_dir, f))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.real_images) + len(self.fake_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "      if idx < len(self.real_images):\n",
        "        img_path = os.path.join(self.real_dir, self.real_images[idx])\n",
        "        label = 0  # Real\n",
        "      else:\n",
        "\n",
        "        img_path = os.path.join(self.fake_dir, self.fake_images[idx - len(self.real_images)])\n",
        "        label = 1  # Fake\n",
        "\n",
        "      #Debugging print\n",
        "      print(f\"Processing file: {img_path}\")\n",
        "\n",
        "      # Check if img_path is a directory\n",
        "      if os.path.isdir(img_path):\n",
        "        raise ValueError(f\"Expected a file but found a directory: {img_path}\")\n",
        "\n",
        "      image = Image.open(img_path).convert('L')  # Convert to grayscale\n",
        "\n",
        "      if self.transform:\n",
        "        image = self.transform(image)\n",
        "\n",
        "      return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNGXq4dMlItR"
      },
      "source": [
        "**GRU Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vstVZcOQ5HB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Define GRU Layer\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = None\n",
        "\n",
        "        # Dynamically calculate the output size for the fully connected layer\n",
        "        dummy_input = torch.randn(1, 1, input_size)  # Assuming 1 time step and input size as sequence length\n",
        "        dummy_out, _ = self.gru(dummy_input)  # Pass through GRU\n",
        "        output_shape = dummy_out.view(1, -1).shape[1]\n",
        "\n",
        "        # Now define the fully connected layer based on the calculated output shape\n",
        "        self.fc = nn.Linear(output_shape, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Reshape x to (batch_size, sequence_length, input_size), assuming (batch_size, 1, 128, 128)\n",
        "        x = x.view(batch_size, 128, 128)\n",
        "\n",
        "        # Initialize hidden state for the GRU layer\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "\n",
        "        # Pass through GRU\n",
        "        out, h_n = self.gru(x, h0)  # Removed Sequential, passing directly through GRU\n",
        "\n",
        "        # We are only interested in the output of the last time step\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Pass through the fully connected layer\n",
        "        out = self.fc(out)\n",
        "        return out, h_n  # Returning hidden state as well\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34UwvEan5zdN"
      },
      "source": [
        "Logging functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivPRuTMW52B1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "def log_weights_biases(model, epoch):\n",
        "    weights_biases = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            weights_biases[name] = param.data.cpu().numpy()  # Move to CPU for easier handling\n",
        "    weights_biases_history.append((epoch, weights_biases))\n",
        "\n",
        "def track_weight_changes(model, epoch):\n",
        "    norms = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            norms[name] = torch.norm(param.data).item()\n",
        "    weight_norms.append((epoch, norms))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive to use images stored on Drive"
      ],
      "metadata": {
        "id": "i1nQ2k3sYm6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lmwlo-BxYq6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cev7kO5EguZ"
      },
      "source": [
        "**DATA Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW_fj9XnEgua"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "import os\n",
        "\n",
        "# Paths to your data folders\n",
        "real_dir = '/content/drive/MyDrive/SauravSir_CodeFiles/Output/real_images_stft' #Path to where real MFCC/STFT/Melspectrograms images are saved; one at a time\n",
        "fake_dir = '/content/drive/MyDrive/SauravSir_CodeFiles/Output/real_images_stft' #Path to where fake MFCC/STFT/Melspectrograms images are saved; one at a time\n",
        "\n",
        "# Image transformations (resizing and converting to tensor)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
        "    transforms.ToTensor()           # Convert images to PyTorch tensors\n",
        "])\n",
        "\n",
        "# Create the dataset\n",
        "dataset = SpectrogramDataset(real_dir, fake_dir, transform=transform)\n",
        "\n",
        "# Split into training and testing sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# DataLoader for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5ZfRouC5w2t"
      },
      "source": [
        "LOG Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3HiR3Xl5yhV"
      },
      "outputs": [],
      "source": [
        "# Initialize storage for weights, biases, weight norms, and hidden states\n",
        "weights_biases_history = []\n",
        "weight_norms = []\n",
        "hidden_states_history = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QIAQzyFEgua"
      },
      "source": [
        "**TRAIN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNaiaxpAEgua"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Model, loss function, optimizer\n",
        "model = GRUModel(input_size=128, hidden_size=64, num_layers=2, num_classes=2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Start time\n",
        "train_start_time = time.time()  # Start timing training\n",
        "\n",
        "# Variables to track accuracy and loss\n",
        "accuracy_list = []\n",
        "loss_list = []\n",
        "hidden_states_history = []\n",
        "num_epochs = 5\n",
        "\n",
        "# Training loop (modified forward pass to capture both outputs and hidden states)\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass (now captures hidden states)\n",
        "        outputs, hidden_states = model(inputs)  # Adjusted to capture hidden states\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Accuracy calculations\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate epoch loss and accuracy\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    accuracy_list.append(epoch_accuracy)\n",
        "    loss_list.append(epoch_loss)\n",
        "\n",
        "    # Log weights, biases, and weight changes\n",
        "    log_weights_biases(model, epoch)\n",
        "    track_weight_changes(model, epoch)\n",
        "\n",
        "    # Store hidden states for visualization\n",
        "    hidden_states_history.append(hidden_states.cpu().detach().numpy())\n",
        "\n",
        "    # Print only one line per epoch\n",
        "    print(f\"\\033[92mEpoch {epoch + 1}/{num_epochs}\\n Loss: {epoch_loss:.4f}\\n Accuracy: {epoch_accuracy:.2f}%\\033[0m\")\n",
        "\n",
        "\n",
        "train_end_time = time.time()  # End timing training\n",
        "print(f\"\\033[1;91mTime taken for training: {train_end_time - train_start_time:.2f} seconds\\033[0m\")\n",
        "\n",
        "# Plot Accuracy and Loss per Epoch\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(1, num_epochs + 1), accuracy_list, marker='o', label='Accuracy')\n",
        "plt.plot(range(1, num_epochs + 1), loss_list, marker='x', label='Loss')\n",
        "plt.title('Training Progress')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Annotate accuracy values on the graph\n",
        "for i, (acc, loss) in enumerate(zip(accuracy_list, loss_list)):\n",
        "    plt.annotate(f'{acc:.2f}', (i + 1, acc), textcoords=\"offset points\", xytext=(0, 5), ha='center')\n",
        "    plt.annotate(f'{loss:.2f}', (i + 1, loss), textcoords=\"offset points\", xytext=(0, -10), ha='center')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCAmv1ntl0d9"
      },
      "source": [
        "**EVALUATE Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wppidz92BPCC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "import torch\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "\n",
        "'''\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)  # Move the model to GPU if available\n",
        "'''\n",
        "\n",
        "# Assuming you already have a loss function defined, e.g.\n",
        "criterion = torch.nn.CrossEntropyLoss()  # or use BCELoss if binary classification\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "total_loss = 0.0\n",
        "\n",
        "eval_start_time = time.time()  # Start timing evaluation\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move to device\n",
        "        outputs, hidden_states = model(inputs)  # Unpack outputs and hidden states\n",
        "\n",
        "        # Check the shape of the outputs\n",
        "        print(f\"Outputs shape: {outputs.shape}\")  # Debugging line\n",
        "\n",
        "        # For multi-class:\n",
        "        if len(outputs.shape) == 2 and outputs.shape[1] > 1:  # Ensure correct shape\n",
        "            _, predicted = torch.max(outputs, 1)  # Get predicted class indices\n",
        "        else:\n",
        "            print(\"Error: Outputs tensor does not have the correct shape for classification.\")\n",
        "            continue  # Skip this iteration if the output shape is incorrect\n",
        "\n",
        "        # For loss computation\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Collect all labels and predictions for metric computation\n",
        "        all_labels.extend(labels.cpu().numpy())  # Move to CPU for compatibility with sklearn\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "print()\n",
        "eval_end_time = time.time()  # End timing evaluation\n",
        "print(f\"\\033[1;92mTime taken for evaluation: {eval_end_time - eval_start_time:.2f} seconds\\033[0m\")\n",
        "print()\n",
        "\n",
        "# Convert to numpy arrays for sklearn\n",
        "all_labels = np.array(all_labels)\n",
        "all_predictions = np.array(all_predictions)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = 100 * correct / total\n",
        "\n",
        "# Precision, Recall, F1 Score\n",
        "precision = precision_score(all_labels, all_predictions, average='macro')  # use 'binary' for binary classification\n",
        "recall = recall_score(all_labels, all_predictions, average='macro')  # use 'binary' for binary classification\n",
        "f1 = f1_score(all_labels, all_predictions, average='macro')  # use 'binary' for binary classification\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Average loss\n",
        "avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "\n",
        "# Data to be displayed in the table\n",
        "data = [\n",
        "    ['Accuracy', f'{accuracy:.2f}%'],\n",
        "    ['Precision', f'{precision:.2f}'],\n",
        "    ['Recall', f'{recall:.2f}'],\n",
        "    ['F1 Score', f'{f1:.2f}'],\n",
        "    ['Loss', f'{avg_loss:.4f}']\n",
        "]\n",
        "\n",
        "# Print the table\n",
        "print(tabulate(data, headers=['Metric', 'Value'], tablefmt='fancy_grid'))\n",
        "print()\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Labels')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}